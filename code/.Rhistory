return (Pchoice)
}
trueProb <- left_join(
ddply(val,.(bucket,choice),summarise,PchoiceBucket = Prob_choice_bucket(choice,bucket)),
Prob_bucket(1:3),
by = "bucket"
) %>%
mutate(prob = PchoiceBucket * Pbucket) %>%
select(bucket,choice,prob)
wald <- function (theta, sigma, H0,rem,n = N){
W<- n * t(theta[-rem] - H0[-rem])%*%
(sigma[-rem,-rem]) %*%
(theta[-rem] - H0[-rem])
return(W)
}
(Truth <- arrange(trueProb,choice,bucket))
W1 <- wald(Prob1$prob, sigma1, Truth$prob,rem=1,n=N)
W1 > qchisq(0.975,8) # Fail to reject the null hypothesis of equal probabilities
W2 <- wald(Prob2$prob,sigma2,Truth$prob,rem=c(1,2,4),n=N)
W2 > qchisq(0.975,6) # Fail to reject the null hypothesis of equal probabilities
trueProb <- left_join(
ddply(val,.(bucket,choice),summarise,PchoiceBucket = Prob_choice_bucket(choice,bucket)),
Prob_bucket(1:3),
by = "bucket"
) %>%
mutate(prob = PchoiceBucket * Pbucket) %>%
select(bucket, choice, prob) %>%
arrange(choice, bucket)
wald <- function (theta, sigma, H0,rem,n = N){
W<- n * t(theta[-rem] - H0[-rem])%*%
(sigma[-rem,-rem]) %*%
(theta[-rem] - H0[-rem])
return(W)
}
W1 <- wald(Prob1$prob, sigma1, Truth$prob,rem=1,n=N)
W1 > qchisq(0.975,8) # Fail to reject the null hypothesis of equal probabilities
W2 <- wald(Prob2$prob,sigma2,Truth$prob,rem=c(1,2,4),n=N)
W2 > qchisq(0.975,6) # Fail to reject the null hypothesis of equal probabilities
a <- matrix(eta,nrow = 3,byrow = TRUE)
eps <- matrix(epsilon,nrow = 3,byrow = TRUE)
U2 <- apply(
val$val +
matrix(rep(epsilon,3),nrow = 9, byrow = TRUE) +
rep(lambda$lambda,3) * a[rep(seq(nrow(a)),each = 3),],2,which.max
)
U3<-
mdply(k_i,
function(k, i)
val[k, i] + eps[,i] + lambda$lambda[k]*a[,i])
View(`U3`)
U3<-
mdply(k_i,
function(k, i)
val[k, toString(i)] + eps[,toString(i)] + lambda$lambda[k]*a[,toString(i)])
k_i
View(eps)
View(a)
U3<-
mdply(k_i,
function(k, i)
val[k, i] + eps[i,] + lambda$lambda[k]*a[i,])
View(`U3`)
val
U3<-
mdply(k_i,
function(k, i)
val$val[bucket==k, choice==i] + eps[i,] + lambda$lambda[k]*a[i,])
U3<-
mdply(k_i,
function(k, i)
val$val["bucket"==k, "choice"==i] + eps[i,] + lambda$lambda[k]*a[i,])
U3<-
mdply(k_i,
function(k, i)
val$val["bucket"==k & "choice"==i] + eps[i,] + lambda$lambda[k]*a[i,])
?outer
?identical
match_df(val, k_i[1,], on = c(bucket, choice))
test<- val(,1:2)
test<- val[],1:]2
test<- val[,1:2
]
test
match_df(val, test[1,], on = c(bucket, choice))
match_df(val, test, on = c(bucket, choice))
match_df(val, test[1,], on = c("bucket", "choice"))
val
match_df(val, c(1,"A"), on = c("bucket", "choice"))
which(val,"bucket"==1)
?which
val[which(val,"bucket"==1)]
val[which("bucket"==1)]
val[which("bucket"==1)]->test
test
View(test)
val[,which("bucket"==1)]->test
View(test)
val[which(val$bucket==1)]
val[which(val$bucket==1)]$bucket
head(U2)
rep(lambda$lambda,nChoices)
rep(lambda$lambda,3)
N <- 10^5
nBuckets <- nrow(lambda)
nChoices <- length(unique(val$choice))
set.seed(1023)
epsilon <- rgev(n = nBuckets*N, xi = 0, mu = 0, beta = 1)
eta <- rgev(n = nChoices*N, xi = 0, mu = 0, beta = 1)
#################################################################################################
# 1 under the traditional specification where epsilon_k resolves before eta_i
# We estimate the inclusive value of each bucket to choose a bucket for each simulation.
# Then we estimate the value of each choice given the bucket selected for each simulation,
# and select the best choice given the bucket.
#################################################################################################
IV <- left_join(val, lambda, by = "bucket") %>%
group_by(bucket) %>%
summarise(lambda = unique(lambda), iv = log(sum(exp(val/lambda)))) %>%
mutate(iv = lambda * iv)
nest_choice <- data.frame(
"bucket" = apply(IV$iv +
matrix(epsilon,nrow = nBuckets,byrow = TRUE),
2,which.max)
)
item_choice1 <- data.frame(
"bucket" = nest_choice$bucket,
"choice" = LETTERS[
apply(
matrix(
left_join(nest_choice,val,by="bucket")$val,
nrow = nChoices,
ncol = N) +
matrix(eta,nrow = nChoices,byrow = TRUE),
2,which.max)
]
)
#################################################################################################
# 2 under the single-shot specification where epsilon_k and eta_i both resolve up front
# We directly estimate the value of each bucket-choice combination for each simulation,
# and select the maximum one.
#################################################################################################
a <- matrix(eta,nrow = nBuckets,byrow = TRUE)
U2 <- apply(val$val +
matrix(rep(epsilon,nBuckets),nrow = nBuckets * nChoices, byrow = TRUE) +
rep(lambda$lambda,nChoices) *
a[rep(seq(nrow(a)),each = 3),],
2,which.max
)
item_choice2 <- data.frame(
"bucket" = val$bucket[U2],
"choice" = val$choice[U2]
)
val
rep(lambda$lambda,nChoices)
matrix(rep(epsilon,nChoices),nrow = nBuckets * nChoices, byrow = TRUE)
test<- matrix(rep(epsilon,nChoices),nrow = nBuckets * nChoices, byrow = TRUE)
View(test)
test2<- a[rep(seq(nrow(a)),each = 3),]
View(test2)
View(val)
View(a)
val$val[val$bucket==1 &val$choice=="A"]
eps <- matrix(epsilon,nrow = nChoices,byrow = TRUE)
U3<-
mdply(k_i,
function(bucket, choice)
val$val[val$bucket==k, val$choice==i] + eps[k,] + lambda$lambda[k]*a[i,])
eps <- matrix(epsilon,nrow = nChoices,byrow = TRUE)
U3<-
mdply(k_i,
function(k, i)
val$val[val$bucket==k, val$choice==i] + eps[k,] + lambda$lambda[k]*a[i,])
eps <- matrix(epsilon,nrow = nChoices,byrow = TRUE)
U3<-
mdply(k_i,
function(k, i)
val$val[val$bucket==k & val$choice==i] + eps[k,] + lambda$lambda[k]*a[i,])
U2==U3
View(`U3`)
?apply
U3<-
apply(mdply(k_i,
function(k, i)
val$val[val$bucket==k & val$choice==i] + eps[k,] + lambda$lambda[k]*a[i,]),
2,which.max)
U3<-mdply(k_i,
function(k, i)
val$val[val$bucket==k & val$choice==i] + eps[k,] + lambda$lambda[k]*a[i,])
View(`U3`)
val
U3<-mdply(k_i,
function(k, i)
val$val[val$bucket==k & val$choice==i] + eps[k,] + lambda$lambda[k]*a[i,])
%>% select(c(-1,-2))
U3<-mdply(k_i,
function(k, i)
val$val[val$bucket==k & val$choice==i] + eps[k,] + lambda$lambda[k]*a[i,])%>% select(c(-1,-2))
U4<-apply(U3,1,which.max)
U4
U4<-apply(U3,2,which.max)
U2==U4
U3<-apply(mdply(k_i,
function(k, i)
val$val[val$bucket==k & val$choice==i] +
eps[k,] +
lambda$lambda[k]*a[i,]
)%>%
select(c(-1,-2)),
2,which.max)
U2==U3
#Nested logit coding assignment
source('header.R')
#Load data
val<-readRDS(paste0(varSave, 'choice_values.rds'))
lambda<-readRDS(paste0(varSave, 'lambda_values.rds'))
# Simulate 10,000 choices corresponding to epsilon and eta values for each choice/bucket:
N <- 10^5
nBuckets <- nrow(lambda)
nChoices <- length(unique(val$choice))
set.seed(1023)
epsilon <- rgev(n = nBuckets*N, xi = 0, mu = 0, beta = 1)
eta <- rgev(n = nChoices*N, xi = 0, mu = 0, beta = 1)
k_i<- array(val[,1:2])
#################################################################################################
# 1 under the traditional specification where epsilon_k resolves before eta_i
# We estimate the inclusive value of each bucket to choose a bucket for each simulation.
# Then we estimate the value of each choice given the bucket selected for each simulation,
# and select the best choice given the bucket.
#################################################################################################
IV <- left_join(val, lambda, by = "bucket") %>%
group_by(bucket) %>%
summarise(lambda = unique(lambda), iv = log(sum(exp(val/lambda)))) %>%
mutate(iv = lambda * iv)
nest_choice <- data.frame(
"bucket" = apply(IV$iv +
matrix(epsilon,nrow = nBuckets,byrow = TRUE),
2,which.max)
)
item_choice1 <- data.frame(
"bucket" = nest_choice$bucket,
"choice" = LETTERS[
apply(
matrix(
left_join(nest_choice,val,by="bucket")$val,
nrow = nChoices,
ncol = N) +
matrix(eta,nrow = nChoices,byrow = TRUE),
2,which.max)
]
)
#################################################################################################
# 2 under the single-shot specification where epsilon_k and eta_i both resolve up front
# We directly estimate the value of each bucket-choice combination for each simulation,
# and select the maximum one.
#################################################################################################
a <- matrix(eta,nrow = nChoices,byrow = TRUE)
U2 <- apply(val$val +
matrix(rep(epsilon,nChoices),nrow = nBuckets * nChoices, byrow = TRUE) +
rep(lambda$lambda,nChoices) *
a[rep(seq(nChoices),each = nBuckets),],
2,which.max
)
#Alternative U2 calc. I think it's a little easier to read? What do you think? The results are identical.
#eps <- matrix(epsilon,nrow = nChoices,byrow = TRUE)
#U3<-apply(mdply(k_i,
#                function(k, i)
#                  val$val[val$bucket==k & val$choice==i] +
#                  eps[k,] +
#                  lambda$lambda[k]*a[i,]
#                )%>%
#                select(c(-1,-2)),
#          2,which.max)
item_choice2 <- data.frame(
"bucket" = val$bucket[U2],
"choice" = val$choice[U2]
)
#################################################################################################
# Estimate the probability of selecting each bucket-choice combination under each of the methods above.
# Also estimate the covariance matrix of estimates with bootstrap.
# Use 100 resamplings of size 100 each for the bootstrap.
#################################################################################################
Prob <- function(k_i, data){
P <- mdply(k_i,
function(k,i) with(data,sum(bucket == k & choice == i)/nrow(data))
)
colnames(P)<- c("bucket", "choice", "prob")
return(P)
}
Prob1 <- Prob(k_i,item_choice1)
Prob2 <- Prob(k_i,item_choice2)
# Bootstrap covariance matrix
b.cov <- function(data, num, size){
resamples <- lapply(1:num, function(i) data[sample(1:nrow(data),size,replace = TRUE),])
r.prob <- sapply(resamples, function(x) Prob(k_i,x)[,3])
covProb <- cov(t(r.prob))
rownames(covProb)<- c("A1","A2","A3","B1","B2","B3","C1","C2","C3")
colnames(covProb)<- c("A1","A2","A3","B1","B2","B3","C1","C2","C3")
return(covProb)
}
sigma1 <- b.cov(item_choice1,100,100)
sigma2 <- b.cov(item_choice2,100,100)
#################################################################################################
# Compute the true, theoretical probability.
# We first calculate the probability of selecting each bucket.
# We then calculate the probabilty of selecting each choice within the bucket.
# The final probability of selecting each bucket-choice combination is the above two probabilities
# multiplied together.
#################################################################################################
Prob_bucket <- function (bucket){
Pbucket = exp(IV$iv[bucket])/sum(exp(IV$iv))
return (data.frame("bucket" = 1:3,Pbucket))
}
Prob_choice_bucket <- function (choice, bucket){
Pchoice <- exp(val$val[val$choice == choice & val$bucket == bucket])/sum(exp(val$val[val$bucket==bucket]))
return (Pchoice)
}
trueProb <- left_join(
ddply(val,.(bucket,choice),summarise,PchoiceBucket = Prob_choice_bucket(choice,bucket)),
Prob_bucket(1:3),
by = "bucket"
) %>%
mutate(prob = PchoiceBucket * Pbucket) %>%
select(bucket, choice, prob) %>%
arrange(choice, bucket)
#################################################################################################
# We calculate the Wald statistic for our estimates using each of the two methods above.
# The hypothesis we are testing is that our estimates are equal to the true, theoretical probs.
# We expect to not reject the hypothesis in the first method, and to reject the hypothesis
# in the second case.
# Our expectations are confirmed.
#################################################################################################
wald <- function (theta, sigma, H0){
W<- t(theta - H0)%*%
ginv(sigma) %*%
(theta - H0)
return(W)
}
W1 <- wald(Prob1$prob, sigma1, trueProb$prob)
1 - pchisq(W1,9) # Fail to reject the null hypothesis of equal probabilities
W2 <- wald(Prob2$prob,sigma2,trueProb$prob)
1 - pchisq(W2,9) # Reject the null hypothesis of equal probabilities
Prob_bucket <- function (bucket){
Pbucket = exp(IV$iv[bucket])/sum(exp(IV$iv))
return (data.frame("bucket" = bucket,Pbucket))
}
Prob_choice_bucket <- function (choice, bucket){
Pchoice <- exp(val$val[val$choice == choice & val$bucket == bucket])/sum(exp(val$val[val$bucket==bucket]))
return (Pchoice)
}
trueProb <- left_join(
ddply(val,.(bucket,choice),summarise,PchoiceBucket = Prob_choice_bucket(choice,bucket)),
Prob_bucket(1:nBuckets),
by = "bucket"
) %>%
mutate(prob = PchoiceBucket * Pbucket) %>%
select(bucket, choice, prob) %>%
arrange(choice, bucket)
View(trueProb)
val
?paste
paste(val$choice, val$bucket, sep = "")
rownames(b.cov)<- paste(val$choice, val$bucket, sep = "")
rownames(b.cov)<- c(paste(val$choice, val$bucket, sep = ""))
rownames(sigma1)<- paste(val$choice, val$bucket, sep = "")
View(sigma1)
#################################################################################################
# Nested logit coding assignment
# Matt Beamer & Cheng-Yu Chan
# 10/24/2014
#################################################################################################
source('header.R')
#Load data
val <-readRDS(paste0(varSave, 'choice_values.rds'))
lambda <-readRDS(paste0(varSave, 'lambda_values.rds'))
# Simulate 10,000 choices corresponding to epsilon and eta values for each choice/bucket:
N <- 10^5
nBuckets <- nrow(lambda)
nChoices <- length(unique(val$choice))
set.seed(1023)
epsilon <- rgev(n = nBuckets * N, xi = 0, mu = 0, beta = 1)
eta <- rgev(n = nChoices * N, xi = 0, mu = 0, beta = 1)
k_i <- array(val[,1:2])
#################################################################################################
# 1 under the traditional specification where epsilon_k resolves before eta_i
# We estimate the inclusive value of each bucket to choose a bucket for each simulation.
# Then we estimate the value of each choice given the bucket selected for each simulation,
# and select the best choice given the bucket.
#################################################################################################
IV <- left_join(val, lambda, by = "bucket") %>%
group_by(bucket) %>%
summarise(lambda = unique(lambda), iv = log(sum(exp(val/lambda)))) %>%
mutate(iv = lambda * iv)
nest_choice <- data.frame(
"bucket" = apply(IV$iv +
matrix(epsilon, nrow = nBuckets, byrow = TRUE),
2, which.max)
)
item_choice1 <- data.frame(
"bucket" = nest_choice$bucket,
"choice" = LETTERS[
apply(
matrix(
left_join(nest_choice,val,by="bucket")$val,
nrow = nChoices,
ncol = N) +
matrix(eta, nrow = nChoices, byrow = TRUE),
2, which.max)
]
)
#################################################################################################
# 2 under the single-shot specification where epsilon_k and eta_i both resolve up front
# We directly estimate the value of each bucket-choice combination for each simulation,
# and select the maximum one.
#################################################################################################
a <- matrix(eta, nrow = nChoices, byrow = TRUE)
eps <- matrix(epsilon, nrow = nChoices, byrow = TRUE)
U2<-apply(mdply(k_i,
function(k, i)
val$val[val$bucket==k & val$choice==i] +
eps[k,] +
lambda$lambda[k]*a[i,]
)%>%
select(c(-1, -2)),
2, which.max)
item_choice2 <- data.frame("bucket" = val$bucket[U2],
"choice" = val$choice[U2]
)
#################################################################################################
# Estimate the probability of selecting each bucket-choice combination under each of the methods above.
# Also estimate the covariance matrix of estimates with bootstrap.
# Use 100 resamplings of size 100 each for the bootstrap.
#################################################################################################
# Calculates sample probabilities:
# - "k_i" : bucket-choice combinations
# - "data": a vector of choices
Prob <- function(k_i, data){
P <- mdply(k_i,
function(k,i) with(data, sum(bucket == k & choice == i)/nrow(data))
)
colnames(P)<- c("bucket", "choice", "prob")
return(P)
}
Prob1 <- Prob(k_i, item_choice1)
Prob2 <- Prob(k_i, item_choice2)
# Bootstraps covariance matrix:
# - "data": a vector of choices
# - "num" : for number of resamplings
# - "size": size of each sample
b.cov <- function(data, num, size){
resamples <- lapply(1:num, function(i) data[sample(1:nrow(data), size, replace = TRUE),])
r.prob <- sapply(resamples, function(x) Prob(k_i, x)[,3])
covProb <- cov(t(r.prob))
rownames(covProb)<- paste(val$choice, val$bucket, sep = "")
colnames(covProb)<- paste(val$choice, val$bucket, sep = "")
return(covProb)
}
sigma1 <- b.cov(item_choice1, 100, 100)
sigma2 <- b.cov(item_choice2, 100, 100)
#################################################################################################
# Compute the true, theoretical probability.
# We first calculate the probability of selecting each bucket.
# We then calculate the probabilty of selecting each choice within the bucket.
# The final probability of selecting each bucket-choice combination is the above two probabilities
# multiplied together.
#################################################################################################
# Calculates probability of selecting each bucket:
# - "bucket": vector of bucket options
Prob_bucket <- function (bucket){
Pbucket = exp(IV$iv[bucket])/sum(exp(IV$iv))
return(data.frame("bucket" = bucket, Pbucket))
}
# Calculates probability of selecting each choice conditional on bucket:
# - "choice": scalar choice option
# - "bucket": scalar bucket option
Prob_choice_bucket <- function (choice, bucket){
Pchoice <- exp(val$val[val$choice == choice & val$bucket == bucket])/
sum(exp(val$val[val$bucket == bucket]))
return(Pchoice)
}
trueProb <- left_join(
ddply(val,.(bucket, choice), summarise, PchoiceBucket = Prob_choice_bucket(choice, bucket)),
Prob_bucket(1:nBuckets),
by = "bucket"
) %>%
mutate(prob = PchoiceBucket * Pbucket) %>%
select(bucket, choice, prob) %>%
arrange(choice, bucket)
#################################################################################################
# We calculate the Wald statistic for our estimates using each of the two methods above.
# The hypothesis we are testing is that our estimates are equal to the true, theoretical probs.
# We expect to not reject the hypothesis in the first method, and to reject the hypothesis
# in the second case.
# Our expectations are confirmed.
#################################################################################################
# Calculates Wald test statistic:
# - "theta": vector of estimated parameters
# - "sigma": matrix of estimated covariance
# - "H0"   : vector of null hypothesis values
wald <- function (theta, sigma, H0){
W<- t(theta - H0)%*%
ginv(sigma) %*%
(theta - H0)
return(W)
}
W1 <- wald(Prob1$prob, sigma1, trueProb$prob)
1 - pchisq(W1, 9) # Fail to reject the null hypothesis of equal probabilities
W2 <- wald(Prob2$prob, sigma2,trueProb$prob)
1 - pchisq(W2, 9) # Reject the null hypothesis of equal probabilities
W1
W2
Prob1
Prob2
trueProb
